# -*- coding: utf-8 -*-
"""22301645_Nabonita_Saha.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GqDlRv2pgdUeKaaIYDQlP_xJSrlof39Z

## Step 1: Load and Preprocess Heart Disease Dataset
"""

import pandas as pd
import numpy as np
import seaborn as sns

# Load dataset
df = pd.read_csv('Heart Disease.csv')
#print(df.head())

# Select features and drop rows with missing important values
df = df[['gender', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds',
         'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP', 'diaBP',
         'BMI', 'heartRate', 'glucose', 'Heart Disease (in next 10 years)']].dropna()


# Convert categorical to numeric
df['gender'] = df['gender'].map({'Male': 1, 'Female': 0})


# Define features and target
X = df.drop('Heart Disease (in next 10 years)', axis=1)
y = df['Heart Disease (in next 10 years)']

"""## Step 2: Train-Test Split + Scaling"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Scale features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""## Step 3: Train Multiple Models"""

from sklearn.linear_model import LogisticRegression
#from sklearn.ensemble import RandomForestClassifier
#from sklearn.svm import SVC
#from sklearn.neighbors import KNeighborsClassifier

# Define models
models = {
    "Logistic Regression": LogisticRegression()
}

"""## Step 4 :Compute ROC & AUC and Plot"""

from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))

for name, model in models.items():
    # Fit
    model.fit(X_train_scaled, y_train)

    # Predict probabilities for class 1 (survived)
    y_probs = model.predict_proba(X_test_scaled)[:, 1]

    # ROC and AUC
    fpr, tpr, _ = roc_curve(y_test, y_probs)
    roc_auc = auc(fpr, tpr)

    # Plot
    plt.plot(fpr, tpr, label=f"{name} (AUC = {roc_auc:.2f})")

# Plot random line
plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')

# Final plot setup
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve Comparison - Titanic Dataset")
plt.legend(loc="lower right")
plt.grid()
plt.show()

"""## Step 5: Interpretation

Closer to top-left = Better performance

AUC Score near 1.0: Excellent model

AUC ~0.5: Useless (like guessing)

## Multiclass Confusion Matrix

## Step 1: Load Data & Split
"""

from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from google.colab import files

# Load digits dataset
digits = files.upload()
df = pd.read_csv('Heart Disease.csv')


df = df[['gender', 'age', 'education', 'currentSmoker', 'cigsPerDay', 'BPMeds',
         'prevalentStroke', 'prevalentHyp', 'diabetes', 'totChol', 'sysBP',
         'diaBP', 'BMI', 'heartRate', 'glucose', 'Heart Disease (in next 10 years)']].dropna()


df['gender'] = df['gender'].map({'Male': 1, 'Female': 0})


x = df.drop('Heart Disease (in next 10 years)', axis=1)
y = df['Heart Disease (in next 10 years)']


# Split into train/test
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)

# Scale for better model performance
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""## Step 2: Train a Models"""

from sklearn.linear_model import LogisticRegression


# Logistic Regression
log_model = LogisticRegression(max_iter=5000)
log_model.fit(X_train, y_train)
y_pred_log = log_model.predict(X_test)

"""## Step 3 : Multiclass Confusion Matrix & Accuracy"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score
import matplotlib.pyplot as plt

# Logistic Regression
cm_log = confusion_matrix(y_test, y_pred_log)

ConfusionMatrixDisplay(cm_log, display_labels=["No heart disease","heart disease"]).plot(cmap="Blues")
plt.title("Logistic Regression Confusion Matrix")
plt.show()


# Accuracy
print("Logistic Regression Accuracy:", accuracy_score(y_test, y_pred_log))

"""## Advanced Evaluation

- **Precision** = What % of predicted positives were *actually* positive?  
  > *"How accurate are my positive predictions?"*

- **Recall** = What % of actual positives were correctly predicted?  
  > *"How well did I find all the real positives?"*

- **F1 Score** = The balance between precision and recall (harmonic mean).  
  > *"How good is the model overall at finding positives accurately?"*

### Formulae:
- Precision = TP / (TP + FP)  
- Recall = TP / (TP + FN)  
- F1 Score = 2 × (Precision × Recall) / (Precision + Recall)

Where:
- TP = True Positives  
- FP = False Positives  
- FN = False Negatives
"""

from sklearn.metrics import classification_report
condition_type=["No heart disease","Heart disease"]
print("Logistic Regression:")
print(classification_report(y_test, y_pred_log, target_names=condition_type))